# event-simulator
Simulator for OS resource sharing
Karl Schaller 915580340

Overview
	The event simulator program was created to demonstrate concepts of virtualization, concurrency, and the sharing of resources by the operating system. Our system in this simulation has four main components: the CPU, Disk 1, Disk 2, and a Network component. The program use queues to allocated these components to processes and release them when the process has finished using it.
	In our simulation, jobs arrive to the system on a uniformly random interval and are placed into the queue to utilize the CPU. After CPU processing, a job may be finished and randomly exit the system. If it does not, it is randomly sent to either the Network component or one of the two disks for a read/write. After this, the job returns to the CPU queue and continues the cycle until the job randomly leaves the system after CPU processing.

Our Method
	The main structure of the program is maintained by a priority queue that represents upcoming events. Each event object in the priority queue has a time at which the event will occur and what type of event it is (a job arriving, a certain component finishing, or the simulation finishing). The priority queue is a linked list sorted by the events’ times, so that whenever a new event is scheduled to occur, it is inserted into its proper position.
	At runtime, two events are added to the event queue: a job arrival at the initial starting time, and a simulation finished event at the finish time. The program then begins removing items from the priority queue one by one. When an event is popped, the proper processing takes place based on the type of event. When a job arrives, the job is sent to the CPU (all four components are represented by FIFO queues) and the next job arrival is scheduled and added to the event queue. If the CPU was empty, processing begins (a CPU finished event is scheduled). If processing finishes at any of the four components, the job is sent to where it needs to go (beginning processing there if need be), and the component checks for the next jobs in its queue to process, scheduling another finish event. These finish times are all determined by generating a random number on an interval for a corresponding component found in the config file. Every event that occurs is recorded into a log file in chronological order.
	As the simulation processes, statistics of the system’s components are collected to be printed upon the simulation finished event. The average size of each component queue could be generated by dividing a sum of the queue size at each moment by the total number of moments. Instead of adding the number of elements in the queue for each moment, we add the number of moments in the queue for each element (response time) by simply noting the time that job arrived in the component’s queue and taking the difference from the time of its finish event once it is being handled (we also update max response time here). This total response time of all jobs is also useful when determining the average response time for a component, where we must divide by the total number of jobs completed rather than the running time of the simulation. This total number of jobs completed is then used for the through put (number of jobs/total time). We check for new max queue size before popping the job for a component’s finish event. And for component utilization, we keep a sum of each components busy time when generating the duration of each process to be divided by the total simulation run time.

Testing 
	The main challenge in verifying that the simulation was working was confirming that the queues were correct after each possible event. While debugging multiple segmentation fault errors, we printed out the various queues before and after performing computations on them to ensure the simulation was proceeding as intended. Once the log file was producing the desired results, we began experimenting with the config and changing component variables to make sure the output would change as expected. Then, we ran the simulation which multiple random seeds and ensured that the statistics were roughly constant throughout tests.
